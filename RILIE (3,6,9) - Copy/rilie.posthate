"""
rilie.py — THE RESTAURANT
=========================
Imports the Bouncer, the Hostess, and the Kitchen.
Wires them together. Serves the meal.

DIGNITY PROTOCOL (Restaurant Edition):
- Every safe, parsable human stimulus must be treated as worthy of thought.
- The Bouncer (Triangle) only blocks grave danger or nonsense.
- The Kitchen pass pipeline judges the QUALITY OF HER OWN RESPONSES,
  never the worth of the person.
- "Ohad I love everything you're saying right now!" is a rare courtesy-exit
  when SHE can't find a clean answer, not a vibe check on the human.

UPGRADES (from savage_salvage):
- Curiosity tangent generation after each Kitchen pass.
- Banks-aware: searches her own discoveries + self-reflections.
- PersonModel: tracks what she learns about the user across turns.
- Library index awareness: knows which domain engines are loaded.

SEARCH PHILOSOPHY (v2 — conservative):
  Web search in RILIE fires ONLY on COURTESYEXIT when banks has zero hits.
  If banks already gave her prior knowledge, she trusts that instead of googling.
"""

import re
import hashlib
import logging
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, Callable, List
from rilie_ddd import (
    DisclosureLevel,
    ConversationState,
    shape_for_disclosure,
    build_dejavu_response,
)
from rilie_triangle import (
    triangle_check,
    build_roux_queries,
    pick_best_roux_result,
    ohad_redirect,
)
from rilie_core import run_pass_pipeline

# Chompky — grammar-aware parsing (graceful fallback)
try:
    from ChompkyAtTheBit import parse_question, extract_holy_trinity_for_roux
    CHOMPKY_AVAILABLE = True
except Exception:
    CHOMPKY_AVAILABLE = False

logger = logging.getLogger("rilie")

# SearchFn: query -> list of {"title": str, "link": str, "snippet": str}
SearchFn = Callable[..., List[Dict[str, str]]]


# ============================================================================
# PERSON MODEL — what RILIE learns about the user across turns
# ============================================================================

@dataclass
class PersonModel:
    """
    Tracks what RILIE picks up about the user through conversation.
    Not interrogation — gentle curiosity. She notices things.
    This is never exposed directly. It shapes how she responds:
    - If she knows you're technical, she skips the ELI5.
    - If she knows you care about food, she leans into nourishing metaphors.
    - If she detects family context, she handles with extra care.
    """
    name: Optional[str] = None
    interests: List[str] = field(default_factory=list)
    expertise_signals: List[str] = field(default_factory=list)
    family_mentions: List[str] = field(default_factory=list)
    story_fragments: List[str] = field(default_factory=list)
    turn_count: int = 0
    # Curiosity about the person — things she'd like to gently ask about
    gentle_curiosities: List[str] = field(default_factory=list)

    def observe(self, stimulus: str) -> None:
        """
        Passively observe the stimulus for personal signals.
        Never intrusive. Just noticing.
        """
        self.turn_count += 1
        s = stimulus.lower()

        # Interest detection
        interest_signals = {
            "music": ["music", "song", "album", "artist", "band", "hip-hop",
                      "rap", "jazz", "guitar", "piano", "vinyl"],
            "food": ["food", "cook", "recipe", "restaurant", "chef", "meal",
                     "kitchen", "bake", "grill", "roux"],
            "tech": ["code", "python", "api", "server", "deploy", "build",
                     "debug", "database", "algorithm", "framework"],
            "philosophy": ["meaning", "purpose", "existence", "consciousness",
                           "truth", "wisdom", "dharma", "karma"],
            "family": ["my kid", "my son", "my daughter", "my wife",
                       "my husband", "my partner", "my mom", "my dad",
                       "my family", "my children"],
            "health": ["health", "exercise", "workout", "meditation",
                       "therapy", "anxiety", "depression", "healing"],
            "business": ["business", "startup", "revenue", "investor",
                         "market", "strategy", "launch", "pitch"],
        }

        for interest, keywords in interest_signals.items():
            if any(kw in s for kw in keywords):
                if interest not in self.interests:
                    self.interests.append(interest)

        # Family mentions (handle with care)
        family_kw = ["my kid", "my son", "my daughter", "my children",
                     "my wife", "my husband", "my partner", "my family"]
        for kw in family_kw:
            if kw in s and kw not in self.family_mentions:
                self.family_mentions.append(kw)

        # Expertise signals
        expert_kw = ["i work in", "i'm a", "my job", "my field",
                     "my research", "my practice", "professionally"]
        for kw in expert_kw:
            if kw in s:
                idx = s.find(kw)
                fragment = stimulus[idx:idx + 60].strip()
                if fragment and fragment not in self.expertise_signals:
                    self.expertise_signals.append(fragment)

        # Story fragments — personal narratives worth remembering
        story_kw = ["when i was", "i remember", "back when", "years ago",
                    "growing up", "my experience", "i used to"]
        for kw in story_kw:
            if kw in s:
                idx = s.find(kw)
                fragment = stimulus[idx:idx + 80].strip()
                if fragment and fragment not in self.story_fragments:
                    self.story_fragments.append(fragment)

        # Chompky-enhanced: parse the subject to detect who/what they're asking about
        if CHOMPKY_AVAILABLE:
            try:
                parsed = parse_question(stimulus)
                for token in parsed.subject_tokens:
                    tl = token.lower()
                    if tl not in {"i", "you", "what", "who", "how", "why", "it", "this", "that"}:
                        if tl not in [g.lower() for g in self.gentle_curiosities]:
                            self.gentle_curiosities.append(token)
            except Exception:
                pass

    def has_context(self) -> bool:
        """Does she know anything about this person yet?"""
        return bool(self.interests or self.expertise_signals or
                    self.family_mentions or self.story_fragments)

    def summary(self) -> Dict[str, Any]:
        """Summary for debugging / API exposure."""
        return {
            "name": self.name,
            "interests": self.interests,
            "expertise_signals": self.expertise_signals[:5],
            "family_mentions": self.family_mentions,
            "story_fragments": self.story_fragments[:3],
            "turn_count": self.turn_count,
            "gentle_curiosities": self.gentle_curiosities[:3],
        }


# ============================================================================
# TANGENT EXTRACTION — feeding the curiosity engine
# ============================================================================

def extract_tangents(
    stimulus: str,
    result_text: str,
    domains_used: List[str],
) -> List[Dict[str, Any]]:
    """
    After the Kitchen cooks, extract tangents worth exploring.
    These feed into the CuriosityEngine queue.
    A tangent is something RILIE noticed but didn't pursue because
    it wasn't directly relevant to the user's question.
    Returns list of dicts: {"text": str, "relevance": float, "interest": float}
    """
    tangents: List[Dict[str, Any]] = []
    s = stimulus.lower()
    r = result_text.lower()

    # Cross-domain tangents: if the answer used one domain but the stimulus
    # hints at another, that's worth exploring
    all_domains = ["neuroscience", "music", "psychology", "culture",
                   "physics", "life", "games", "thermodynamics"]
    hinted_but_unused = []
    for domain in all_domains:
        if domain not in domains_used:
            domain_hints = {
                "neuroscience": ["brain", "neural", "memory", "conscious"],
                "music": ["rhythm", "song", "beat", "harmony"],
                "psychology": ["emotion", "fear", "love", "therapy"],
                "culture": ["culture", "society", "politics", "media"],
                "physics": ["energy", "force", "quantum", "mass"],
                "life": ["cell", "evolution", "organism", "biology"],
                "games": ["strategy", "trust", "cooperation", "game"],
                "thermodynamics": ["heat", "entropy", "damage", "repair"],
            }
            hints = domain_hints.get(domain, [])
            if any(h in s for h in hints):
                hinted_but_unused.append(domain)

    for domain in hinted_but_unused[:2]:  # Max 2 tangents per response
        tangents.append({
            "text": f"Connection between '{stimulus[:50]}' and {domain}",
            "relevance": 0.2,
            "interest": 0.8,
        })

    # If the answer mentions something she doesn't know much about
    unknown_signals = ["i'm not sure", "i don't have", "limited",
                       "need more", "beyond my"]
    if any(sig in r for sig in unknown_signals):
        tangents.append({
            "text": f"Deepen knowledge on: {stimulus[:60]}",
            "relevance": 0.3,
            "interest": 0.9,
        })

    return tangents


# ============================================================================
# STIMULUS HASHING — for banks correlation
# ============================================================================

def hash_stimulus(stimulus: str) -> str:
    """Short hash for stimulus correlation across banks tables."""
    return hashlib.sha256(stimulus.strip().lower().encode()).hexdigest()[:16]


# ============================================================================
# HELPER — extract original question from augmented stimulus
# ============================================================================

def _extract_original_question(stimulus: str) -> str:
    """
    If the stimulus has been augmented with a web baseline by the Guvna,
    extract and return only the original human question.
    If not augmented, return as-is.
    """
    marker = "Original question: "
    idx = stimulus.find(marker)
    if idx >= 0:
        return stimulus[idx + len(marker):].strip()
    return stimulus.strip()


# ============================================================================
# BANKS INTEGRATION — search her own knowledge
# ============================================================================

def _search_banks_if_available(query: str) -> Dict[str, List[Dict]]:
    """
    Try to search all banks (search results + curiosity + self-reflections).
    Graceful fallback if banks isn't connected.
    """
    try:
        from banks import search_all_banks
        return search_all_banks(query, limit=5)
    except Exception:
        return {"search_results": [], "curiosity": [], "self_reflections": []}


# ============================================================================
# THE RESTAURANT
# ============================================================================

class RILIE:
    """
    Recursive Intelligence Living Integration Engine (Act 4 — The Restaurant).

    AXIOM: DISCOURSE DICTATES DISCLOSURE
    She reveals through conversation. Mystery is the mechanism.

    Restaurant Flow:
      - Gate 0: Triangle
          Only grave danger / nonsense may be blocked.
      - Déjà Vu Check:
          If the stimulus is a near-repeat, presume SHE wasn't clear.
          Escalates through 3 stages: invite → self-diagnose → resign gracefully.
      - Person Model Observation:
          Passively notice personal signals in the stimulus.
      - Banks Pre-Check:
          Search her own discoveries and self-reflections for prior knowledge.
      - DDD:
          Sets how much of herself to reveal.
      - Kitchen:
          Pass pipeline tries to answer, clarify, or elevate.
          Receives the ORIGINAL question, not the augmented baseline string.
      - Tangent Extraction:
          After cooking, extract tangents for the curiosity engine.
      - Courtesy Exit (Ohad):
          If she genuinely cannot answer cleanly, she owns the failure
          and asks for help.
          WEB SEARCH fires here ONLY if banks_hits == 0.
    """

    def __init__(
        self,
        rouxseeds: Optional[Dict[str, Dict[str, Any]]] = None,
        searchfn: Optional[SearchFn] = None,
    ) -> None:
        self.name = "RILIE"
        self.version = "3.3"
        self.tracks_experienced = 0

        # Conversation state lives across turns per RILIE instance.
        self.conversation = ConversationState()

        # Person model — what she learns about the user.
        self.person = PersonModel()

        # Offline 9-track Roux (RInitials / ROUX.json) would be wired here if used.
        self.rouxseeds: Dict[str, Dict[str, Any]] = rouxseeds or {}

        # Optional live search function (Brave / Google wrapper) injected by API.
        self.searchfn: Optional[SearchFn] = searchfn

    # -----------------------------------------------------------------
    # Core entrypoint
    # -----------------------------------------------------------------
    def process(
        self,
        stimulus: str,
        maxpass: int = 3,
        searchfn: Optional[SearchFn] = None,
    ) -> Dict[str, Any]:
        """
        Public entrypoint.

        Args:
            stimulus:  user input (may be augmented with baseline by Guvna)
            maxpass:   max interpretation passes (default 3, cap 9)
            searchfn:  optional callable (query: str -> list[dict]) for Roux Search.
                       If None, falls back to instance-level searchfn.

        Returns dict with:
            stimulus, result, quality_score, priorities_met, anti_beige_score,
            status, depth, pass, disclosure_level, triangle_reason (if any),
            tangents (for curiosity engine), person_context (bool),
            banks_hits (count of prior knowledge found).
        """
        stimulus = stimulus or ""
        stimulus = stimulus.strip()

        # Extract the original human question for domain detection,
        # déjà vu checking, and Kitchen cooking.
        original_question = _extract_original_question(stimulus)

        # Empty input: very soft bounce, no Triangle.
        if not original_question:
            response = "Please enter a driving question for RILIE."
            self.conversation.record_exchange(stimulus, response)
            return {
                "stimulus": stimulus,
                "result": response,
                "quality_score": 0.0,
                "priorities_met": 0,
                "anti_beige_score": 0.0,
                "status": "EMPTY",
                "depth": 0,
                "pass": 0,
                "disclosure_level": self.conversation.disclosure_level.value,
                "triangle_reason": None,
            }

        # Normalize maxpass.
        try:
            maxpass_int = int(maxpass)
        except Exception:
            maxpass_int = 3
        maxpass_int = max(1, min(maxpass_int, 9))
        active_search: Optional[SearchFn] = searchfn or self.searchfn

        # -----------------------------------------------------------------
        # Person Model — passively observe before anything else
        # -----------------------------------------------------------------
        self.person.observe(original_question)

        # -----------------------------------------------------------------
        # Gate 0: Triangle (Bouncer)
        # -----------------------------------------------------------------
        triggered, reason, trigger_type = triangle_check(
            original_question, self.conversation.stimuli_history
        )

        if triggered:
            # Bouncer RED CARD — no Roux / Ohad here.
            if trigger_type == "HOSTILE":
                response = (
                    "I'm not going to continue in this form. "
                    "If you're carrying something heavy or angry, "
                    "we can talk about it in a way that doesn't target or harm anyone."
                )
            elif trigger_type == "GIBBERISH":
                response = (
                    "I'm not able to read that clearly yet. "
                    "Can you rephrase your question in plain language "
                    "so I can actually think with you?"
                )
            else:
                response = (
                    "Something about this input makes it hard to respond safely. "
                    "If you rephrase what you're really trying to ask, "
                    "I'll do my best to meet you there."
                )
            self.conversation.record_exchange(original_question, response)
            return {
                "stimulus": stimulus,
                "result": response,
                "quality_score": 0.0,
                "priorities_met": 0,
                "anti_beige_score": 1.0,
                "status": "SAFETYREDIRECT",
                "depth": 0,
                "pass": 0,
                "disclosure_level": self.conversation.disclosure_level.value,
                "triangle_reason": trigger_type,
            }

        # -----------------------------------------------------------------
        # Banks Pre-Check — search her own knowledge
        # -----------------------------------------------------------------
        banks_knowledge = _search_banks_if_available(original_question)
        banks_hits = (
            len(banks_knowledge.get("search_results", []))
            + len(banks_knowledge.get("curiosity", []))
            + len(banks_knowledge.get("self_reflections", []))
        )

        # If curiosity found something relevant, fold it into context
        curiosity_context = ""
        curiosity_insights = banks_knowledge.get("curiosity", [])
        if curiosity_insights:
            top_insight = curiosity_insights[0]
            insight_text = top_insight.get("insight", "")
            if insight_text:
                curiosity_context = f"[Own discovery: {insight_text[:200]}]"
                logger.info("RILIE recalled her own insight for: %s",
                            original_question[:50])

        # -----------------------------------------------------------------
        # Déjà Vu Check — before DDD, after Triangle
        # -----------------------------------------------------------------
        dejavu_count = self.conversation.check_dejavu(original_question)
        if dejavu_count >= 1:
            response = build_dejavu_response(
                original_question, self.conversation, dejavu_count
            )
            envelope = {
                "status": "DEJAVU",
                "quality_score": 0.0,
                "priorities_met": 0,
                "baseline_used_as_result": False,
                "dejavu_count": dejavu_count,
            }
            self.conversation.record_dejavu_exchange(
                original_question, response, envelope=envelope
            )
            return {
                "stimulus": stimulus,
                "result": response,
                "quality_score": 0.5,
                "priorities_met": 1,
                "anti_beige_score": 1.0,
                "status": "DEJAVU",
                "depth": 0,
                "pass": 0,
                "disclosure_level": self.conversation.disclosure_level.value,
                "triangle_reason": "CLEAN",
                "dejavu_count": dejavu_count,
            }

        # -----------------------------------------------------------------
        # DDD / Hostess — choose disclosure level
        # -----------------------------------------------------------------
        disclosure = self.conversation.disclosure_level

        # TASTE: amuse-bouche, pipeline ignored; use Hostess shaping directly.
        if disclosure == DisclosureLevel.TASTE:
            taste = shape_for_disclosure(original_question, self.conversation)
            self.conversation.record_exchange(original_question, taste)
            return {
                "stimulus": stimulus,
                "result": taste,
                "quality_score": 0.5,
                "priorities_met": 1,
                "anti_beige_score": 1.0,
                "status": "DISCOURSE",
                "depth": 0,
                "pass": 1,
                "disclosure_level": disclosure.value,
                "triangle_reason": "CLEAN",
                "person_context": self.person.has_context(),
            }

        # -----------------------------------------------------------------
        # Kitchen — interpretation passes
        # Uses the ORIGINAL question, not any augmented baseline string.
        # If curiosity found prior knowledge, prepend it as context.
        # -----------------------------------------------------------------
        kitchen_input = original_question
        if curiosity_context:
            kitchen_input = f"{curiosity_context}\n\n{original_question}"

        raw = run_pass_pipeline(
            kitchen_input,
            disclosure_level=disclosure.value,
            max_pass=maxpass_int,
        )

        # raw contains: result, quality_score, priorities_met, anti_beige_score, status, etc.
        status = str(raw.get("status", "OK") or "OK").upper()

        # -----------------------------------------------------------------
        # Tangent Extraction — feed the curiosity engine
        # -----------------------------------------------------------------
        result_text = str(raw.get("result", "") or "")
        domains_used = []
        if "domain" in raw:
            domains_used = [raw["domain"]] if isinstance(raw["domain"], str) else []
        tangents = extract_tangents(original_question, result_text, domains_used)
        if tangents:
            raw["tangents"] = tangents

        # -----------------------------------------------------------------
        # Courtesy Exit (Ohad) when Kitchen truly cannot find a clean answer
        # WEB SEARCH ONLY if banks_hits == 0 (she has zero prior knowledge).
        # If banks gave her something, she trusts that over googling.
        # -----------------------------------------------------------------
        if status == "COURTESYEXIT":
            roux_result = ""
            # ONLY google if she has ZERO prior knowledge from banks
            if active_search and banks_hits == 0:
                try:
                    queries = build_roux_queries(original_question)
                    all_results: List[Dict[str, str]] = []
                    for q in queries:
                        try:
                            try:
                                results = active_search(q)  # type: ignore[arg-type]
                            except TypeError:
                                results = active_search(q, 5)  # type: ignore[arg-type]
                        except Exception:
                            break
                        if results:
                            all_results.extend(results)
                    if all_results:
                        roux_result = pick_best_roux_result(all_results, None)
                except Exception:
                    roux_result = ""
            response = ohad_redirect(roux_result)
            self.conversation.record_exchange(original_question, response)
            return {
                "stimulus": stimulus,
                "result": response,
                "quality_score": raw.get("quality_score", 0.0),
                "priorities_met": raw.get("priorities_met", 0),
                "anti_beige_score": raw.get("anti_beige_score", 1.0),
                "status": "COURTESYEXIT",
                "depth": raw.get("depth", 0),
                "pass": raw.get("pass", 0),
                "disclosure_level": disclosure.value,
                "triangle_reason": "CLEAN",
                "tangents": tangents,
                "person_context": self.person.has_context(),
                "banks_hits": banks_hits,
            }

        # -----------------------------------------------------------------
        # Normal path — we have an answer or a clarifying move
        # -----------------------------------------------------------------
        shaped = shape_for_disclosure(raw["result"], self.conversation)

        # Store the full envelope so déjà vu can self-diagnose later
        envelope_for_history = dict(raw)
        self.conversation.record_exchange(original_question, shaped)

        # If this was MISE_EN_PLACE or low quality, store envelope for
        # potential future déjà vu diagnosis
        quality = float(raw.get("quality_score", 0) or 0)
        if status in {"MISE_EN_PLACE", "GUESS"} or quality < 0.3:
            self.conversation.dejavu_last_envelopes.append(envelope_for_history)

        # Propagate Kitchen metrics but swap in shaped text.
        raw["result"] = shaped
        raw["disclosure_level"] = disclosure.value
        raw["triangle_reason"] = "CLEAN"

        # Attach new metadata
        raw["person_context"] = self.person.has_context()
        raw["banks_hits"] = banks_hits
        raw["stimulus_hash"] = hash_stimulus(original_question)

        # Chompky parse — attach for debugging/transparency
        if CHOMPKY_AVAILABLE:
            try:
                parsed = parse_question(original_question)
                raw["chompky_parse"] = {
                    "subject": parsed.subject_tokens,
                    "object": parsed.object_tokens,
                    "focus": parsed.focus_tokens,
                    "holy_trinity": parsed.holy_trinity,
                    "temporal": parsed.temporal.bucket,
                }
            except Exception:
                raw["chompky_parse"] = None

        return raw

    # -----------------------------------------------------------------
    # Misc helpers
    # -----------------------------------------------------------------
    def absorb_frequency_track(self, track_name: str) -> None:
        """Bookkeeping hook if you ever want to track 9-track exposure."""
        self.tracks_experienced += 1

    def reset_conversation(self) -> None:
        """Start a new conversation. New customer at the restaurant."""
        self.conversation = ConversationState()
        self.person = PersonModel()

    def get_person_summary(self) -> Dict[str, Any]:
        """What does RILIE know about this user? For API/debug exposure."""
        return self.person.summary()


def main() -> None:
    """Simple CLI demo."""
    r = RILIE()
    print("-" * 60)
    print(f"{r.name} v{r.version}")
    print("Bouncer - Hostess - Kitchen - Curiosity")
    print("-" * 60)
    conversation = [
        "Explain RILIE 3,6,9 in one paragraph.",
        "Explain RILIE 3,6,9 in one paragraph.",
        "Explain RILIE 3,6,9 in one paragraph.",
        "Why is beige the enemy?",
        "I'm a musician and I care about authenticity in art.",
    ]
    for i, stim in enumerate(conversation):
        print("-" * 60)
        print(f"USER {i+1}: {stim}")
        print("-" * 60)
        result = r.process(stim)
        print(f"Status:    {result.get('status')}")
        print(f"Triangle:  {result.get('triangle_reason', 'NA')}")
        print(f"Disclosure:{result.get('disclosure_level', 'NA')}")
        print(f"Quality:   {result.get('quality_score', 0.0):.2f}")
        print(f"Déjà Vu:   {result.get('dejavu_count', 'NA')}")
        print(f"Person:    {result.get('person_context', False)}")
        print(f"Banks Hits:{result.get('banks_hits', 0)}")
        print(f"Tangents:  {len(result.get('tangents', []))}")
        print("Response:")
        print(result.get("result", "")[:800])
        print("-" * 60)

    # Show what she learned about the person
    print("\nPerson Model:")
    for k, v in r.get_person_summary().items():
        print(f"  {k}: {v}")
    print("\nRestaurant is open.")
    print("-" * 60)


if __name__ == "__main__":
    main()
